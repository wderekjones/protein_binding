{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import initializers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from utils.input_pipeline import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer, Normalizer\n",
    "from keras.objectives import kullback_leibler_divergence\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imputer = Imputer()\n",
    "normalizer = Normalizer()\n",
    "pre_processing_pipeline = Pipeline([('imputer', imputer), ('normalizer', normalizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load_data_t0 = time.clock()\n",
    "#df = pd.concat([pd.read_csv(filename, index_col=[1,0], na_values=['na'], engine='c', header=0) for filename in glob.glob(\"data/parser_output/csv/*.csv\")],axis=0)\n",
    "#df = pd.read_csv(\"data/parser_output/csv/new_mol2_full_feature_-017.csv\", index_col=[1,0], na_values=['na'], engine='c',header=0)\n",
    "#load_data_t1 = time.clock()\n",
    "#print (\"data loaded in ~\", ((load_data_t1 - load_data_t0)/60), \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.input_pipeline import load_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/preprocessed_features.csv\", \"r\") as input_file:\n",
    "    feature_list = []\n",
    "    for line in input_file:\n",
    "        line = line.strip('\\n')\n",
    "        feature_list.append(line)\n",
    "        \n",
    "print(len(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the generator is probably the only valuable thing in this notebook, put this in the input pipeline module\n",
    "def data_gen(file_path, batch_steps,categorical=False, sample_size=None, features_list=None, mode=None, conformation=None):\n",
    "    #decide upon receptor versus protein for naming conventions\n",
    "    receptor_list = list(h5py.File(file_path,'r'))\n",
    "    while(1):\n",
    "        random.shuffle(receptor_list)\n",
    "        \n",
    "        X,y = load_protein(file_path, protein_name=receptor_list[0], sample_size=None,\n",
    "                               features_list=features_list,mode=mode, conformation=conformation)\n",
    "        X = Normalizer().fit_transform(Imputer(strategy=\"median\").fit_transform(np.nan_to_num(X)))\n",
    "        y = y.flatten()\n",
    "        \n",
    "        positives = X[y==1,:]\n",
    "        negatives = X[y==0,:]\n",
    "        for step in range(batch_steps):\n",
    "            negatives_to_keep = np.random.choice(negatives.shape[0],sample_size,replace = True)\n",
    "\n",
    "            X_batch = np.vstack((negatives[negatives_to_keep],positives))\n",
    "            X_batch = np.vstack((X_batch,positives))\n",
    "            y_batch = np.hstack((y[y==0][negatives_to_keep],y[y==1]))\n",
    "            y_batch = np.hstack((y_batch,y[y==1]))\n",
    "            if categorical is True:\n",
    "                yield X_batch, to_categorical(y_batch)\n",
    "            else:\n",
    "                yield X_batch, y_batch\n",
    " \n",
    "#using for debugging purposes\n",
    "#next(data_gen(\"data/full_26_kinase_data.h5\", 10))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    y_true = K.cast(K.argmax(y_true),'float32')\n",
    "    y_pred = K.cast(K.argmax(y_pred), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    y_true = K.cast(K.argmax(y_true),'float32')\n",
    "    y_pred = K.cast(K.argmax(y_pred), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.cast(recall,'float32')\n",
    "\n",
    "def f1(y_true,y_pred):\n",
    "    y_true = K.cast(K.argmax(y_true),'float32')\n",
    "    y_pred = K.cast(K.argmax(y_pred), 'float32')\n",
    "    return K.cast(2*((precision(y_true,y_pred)*recall(y_true,y_pred))/\n",
    "                     (precision(y_true,y_pred)+recall(y_true,y_pred))),'float32')\n",
    "\n",
    "\n",
    "def load_myloss(weights=None):\n",
    "    if weights is None:\n",
    "        class_weights = [0.25, 1]\n",
    "    else:\n",
    "        class_weights = weights\n",
    "\n",
    "    def balanced_loss(y_true, y_pred):\n",
    "\n",
    "        loss_prelim = K.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "        weight = K.cast(K.sum(y_true * class_weights), 'float32')\n",
    "\n",
    "        # apply weight and average \n",
    "        loss_final = K.cast(K.mean(loss_prelim * weight), 'float32')\n",
    "\n",
    "        return loss_final\n",
    "\n",
    "    return balanced_loss\n",
    "\n",
    "\n",
    "def my_loss():\n",
    "    \n",
    "    def custom_loss(y_true,y_pred):\n",
    "        #kl_loss = kullback_leibler_divergence(y_true,y_pred)\n",
    "        #total_loss = kullback_leibler_divergence(y_pred,y_true) + kl_loss\n",
    "        #return total_loss\n",
    "        return K.log(-K.dot(y_true,K.transpose(y_pred)))\n",
    "        \n",
    "        \n",
    "    return custom_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"data/random_forest_features_x_train.txt\",delimiter=\",\",dtype=np.float32)\n",
    "X_test = np.loadtxt(\"data/random_forest_features_x_test.txt\",delimiter=\",\", dtype=np.float32)\n",
    "y_train = np.loadtxt(\"data/random_forest_features_y_train.txt\",delimiter=\",\",dtype=np.float32)\n",
    "y_test = np.loadtxt(\"data/random_forest_features_y_test.txt\",delimiter=\",\",dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14884, 1260) (14884,)\n"
     ]
    }
   ],
   "source": [
    "X_train_pos = X_train[y_train == 1]\n",
    "X_train_neg = X_train[y_train == 0]\n",
    "balanced_X_train = np.random.choice(np.arange(int(np.floor(X_train_neg.shape[0]/2))),size=X_train_pos.shape[0])\n",
    "X_train_neg = X_train_neg[balanced_X_train]\n",
    "X_train_prime = np.vstack((X_train_pos,X_train_neg))\n",
    "y_train_prime = np.hstack((y_train[y_train==1],y_train[y_train==0][balanced_X_train]))\n",
    "print(X_train_prime.shape,y_train_prime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=1260, kernel_regularizer=keras.regularizers.l2(0.)))  \n",
    "model.add(PReLU())\n",
    "model.add(Dense(50))\n",
    "model.add(PReLU())\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=1e-5), metrics=[\"accuracy\",f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2abc53666400>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_prime,y_train_prime, shuffle=True,epochs=1000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of binary and continuous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-307d8d4e5ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\tf1-score:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/cori/software/python/3.5-anaconda/envs/deeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/cori/software/python/3.5-anaconda/envs/deeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/cori/software/python/3.5-anaconda/envs/deeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/cori/software/python/3.5-anaconda/envs/deeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of binary and continuous"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "f1 = f1_score(y_test,model.predict(X_test))\n",
    "acc = accuracy_score(y_test,model.predict(X_test),y_test)\n",
    "print(\"accuracy:\",acc,\"\\tf1-score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.fit_generator(data_gen('data/full_26_kinase_data.h5',categorical=True,\n",
    "#                             sample_size=1000, batch_steps=20000, features_list=feature_list),epochs=10,steps_per_epoch=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score, f1_score\n",
    "#preds = model.predict(X_test)\n",
    "\n",
    "#print(\"accuracy:\",accuracy_score(preds,y_test), \"\\t\",\"f1-score:\",f1_score(preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning (3.5)",
   "language": "python",
   "name": "deeplearning3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
