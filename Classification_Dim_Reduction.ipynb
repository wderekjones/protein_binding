{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation of Classifiers on full dataset (05/17/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are details of my experiments using the Random Forest, Logistic Regression and Multilayer Percpetron learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe24fe607b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from utils import load_data_h5, combine_positive_negative_data\n",
    "from keras_utils import precision, recall\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "cmap = cm.Spectral\n",
    "m = cm.ScalarMappable(norm=norm, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in  1.7797090000000004  seconds.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b023ef861b6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data loaded in \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_positive_negative_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_positive_negative_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carl/workspace/protein_binding/utils.py\u001b[0m in \u001b[0;36mcombine_positive_negative_data\u001b[0;34m(positive, negative)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# TODO: take a list of positives and negatives as args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carl/workspace/protein_binding/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# TODO: take a list of positives and negatives as args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "random_state = 0\n",
    "t0 = time.clock()\n",
    "X_p, y_p = load_data_h5(\"data/ml_pro_features_labels.h5\", mode=1)\n",
    "X_n, y_n = load_data_h5(\"data/ml_pro_features_labels.h5\", mode=0)\n",
    "\n",
    "print(\"Data loaded in \", (time.clock() - t0), \" seconds.\")\n",
    "\n",
    "X = combine_positive_negative_data(X_n, X_p)\n",
    "y = combine_positive_negative_data(y_n, y_p)\n",
    "\n",
    "t1 = time.clock()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "t2 = time.clock()\n",
    "\n",
    "\n",
    "print (\"Train-Test split: \",X_train.shape[0], \"(train)\",\"\\t\",X_test.shape[0], \"(test)\")\n",
    "print(\"Train-Test split completed in \", (t1-t2), \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic0 = LogisticRegression(random_state=random_state)\n",
    "t5 = time.clock()\n",
    "logistic0.fit(X_train, y_train)\n",
    "print (\"Logistic Regression trained on full features in \", (time.clock() - t5), \" seconds.\")\n",
    "logistic_preds0 = logistic0.predict(X_test)\n",
    "generate_report(\"Logistic: Full Features\", logistic0, logistic_preds0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "\n",
    "model0.add(Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='sigmoid'))\n",
    "model0.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model0.compile(optimizer=Adam(lr=1e-4), loss=losses.binary_crossentropy, metrics=[precision, recall])\n",
    "\n",
    "print(model0.summary())\n",
    "t7 = time.clock()\n",
    "model0.fit(X_train, y_train, batch_size=1000, epochs=100, validation_split=0.25, callbacks=[EarlyStopping()])\n",
    "print (\"MLP trained on full features in \", (time.clock() - t7), \" seconds\")\n",
    "\n",
    "preds = model0.predict(X_test)\n",
    "\n",
    "preds[preds >= 0.5] = 1\n",
    "preds[preds < 0.5] = 0\n",
    "generate_report(\"MLP: Full Features\", model0, preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multilayer perceptron outperforms the logistic regression in terms of correctly distinguishing true positives from false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest0 = RandomForestClassifier(max_depth=16,random_state=random_state)\n",
    "t1 = time.clock()\n",
    "rforest0.fit(X_train, y_train)\n",
    "print (\"Random forest trained on full features in \", (time.clock() - t1), \" seconds.\")\n",
    "rforest_preds0 = rforest0.predict(X_test)\n",
    "generate_report(\"Random Forest: Full Features\", rforest0, rforest_preds0, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest is perhaps unsurprisingly able to improve upon the results of the multilayer perceptron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_p, y_p = load_data_h5(\"data/ml_pro_features_labels.h5\", mode=1)\n",
    "X_n, y_n = load_data_h5(\"data/ml_pro_features_labels.h5\", mode=0)\n",
    "\n",
    "\n",
    "X = combine_positive_negative_data(X_n, X_p)\n",
    "y = combine_positive_negative_data(y_n, y_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Dimensionality Reduction (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_norm = normalize(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "reduced_x_ = pca.fit_transform(X_norm)\n",
    "\n",
    "reconstructed_x = pca.inverse_transform(reduced_x_)\n",
    "\n",
    "error = mean_squared_error(X_norm,reconstructed_x)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_x_ = pd.DataFrame(reduced_x_)\n",
    "\n",
    "\n",
    "y_labels = pd.DataFrame(y)\n",
    "\n",
    "plt.clf()\n",
    "sm = pd.plotting.scatter_matrix(reduced_x_,alpha=0.2, c = y_labels[0],figsize=(12,12),diagonal='kde')\n",
    "\n",
    "[s.xaxis.label.set_rotation(45) for s in sm.reshape(-1)]\n",
    "[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]\n",
    "\n",
    "#May need to offset label when rotating to prevent overlap of figure\n",
    "[s.get_yaxis().set_label_coords(-0.3,0.5) for s in sm.reshape(-1)]\n",
    "\n",
    "#Hide all ticks\n",
    "[s.set_xticks(()) for s in sm.reshape(-1)]\n",
    "[s.set_yticks(()) for s in sm.reshape(-1)]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear Dimensionality Reduction\n",
    "Due to limitations in the scikit-learn dimensionality reduction techniques, an autoencoder deep network is trained to perform the non-linear dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import objectives\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from sklearn.preprocessing import normalize\n",
    "from utils import load_data_h5\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "time_stamp = time.clock()\n",
    "\n",
    "\n",
    "X_,y_ = load_data_h5(\"data/ml_pro_features_labels.h5\")\n",
    "X_ = normalize(X_)\n",
    "\n",
    "num_epochs = 1000\n",
    "encoding_dim = 2\n",
    "learning_rate = 1e-2\n",
    "\n",
    "input_data = Input(shape=(188,))\n",
    "alpha = 'glorot_uniform'\n",
    "\n",
    "encoded = Dense(100)(input_data)\n",
    "encoded = PReLU(alpha_initializer=alpha)(encoded)\n",
    "encoded = Dense(50)(encoded)\n",
    "encoded = PReLU(alpha_initializer=alpha)(encoded)\n",
    "encoded = Dense(25)(encoded)\n",
    "encoded = PReLU(alpha_initializer=alpha)(encoded)\n",
    "encoded = Dense(encoding_dim)(encoded)\n",
    "encoded = PReLU(alpha_initializer=alpha)(encoded)\n",
    "\n",
    "decoded = Dense(25)(encoded)\n",
    "decoded = PReLU(alpha_initializer=alpha)(decoded)\n",
    "decoded = Dense(50)(decoded)\n",
    "decoded = PReLU(alpha_initializer=alpha)(decoded)\n",
    "decoded = Dense(100)(decoded)\n",
    "decoded = PReLU(alpha_initializer=alpha)(decoded)\n",
    "decoded = Dense(188)(decoded)\n",
    "decoded = PReLU(alpha_initializer=alpha)(decoded)\n",
    "\n",
    "autoencoder = Model(input_data, decoded)\n",
    "print (autoencoder.summary())\n",
    "\n",
    "encoder = Model(input_data, encoded)\n",
    "print (encoder.summary())\n",
    "\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "\n",
    "decoder = Model(encoded_input,autoencoder.layers[-1](autoencoder.layers[-2](autoencoder.layers[-3](autoencoder.layers[-4](\n",
    "    autoencoder.layers[-5](autoencoder.layers[-6](autoencoder.layers[-7](autoencoder.layers[-8](encoded_input)))))))))\n",
    "\n",
    "print (decoder.summary())\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer=optimizers.adam(lr=learning_rate),loss=objectives.mean_squared_error)\n",
    "\n",
    "\n",
    "autoencoder.fit(X_,X_,epochs=num_epochs,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[ModelCheckpoint(str(time_stamp)+\"_model.h5\")])\n",
    "\n",
    "reduced_x = encoder.predict(X_)\n",
    "plt.clf()\n",
    "plt.scatter(reduced_x[:,0],reduced_x[:,1],c = y_,s=10)\n",
    "plt.savefig(str(time_stamp)+\"_final_dim_reduction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
